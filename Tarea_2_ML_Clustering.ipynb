{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G10v4l4rc0n/Tarea2_MachineLearning/blob/fernando/Tarea_2_ML_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semillas"
      ],
      "metadata": {
        "id": "Eu0aywlLj0bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.cluster import pair_confusion_matrix, contingency_matrix\n",
        "\n",
        "######IMPORTACIÓN Y TRANSFORMACIÓN DE DATASET A DATAFRAME\n",
        "#IMPORTACIÓN\n",
        "with open(\"seeds_dataset.txt\", 'r') as file:\n",
        "    data_list = re.split('\\t|\\n', file.read())\n",
        "\n",
        "#TRANSFORMACIÓN A LISTA\n",
        "copy = data_list.copy()\n",
        "for value in copy:\n",
        "    try:\n",
        "        index_to_remove = copy.index('')\n",
        "    except:\n",
        "        break\n",
        "    else:\n",
        "        copy.remove('')\n",
        "\n",
        "for index in range(len(copy)):\n",
        "    copy[index] = float(copy[index])\n",
        "\n",
        "#TRANSFORMACIÓN A DATAFRAME\n",
        "final_list, sub_list = [], []\n",
        "cont = 0;\n",
        "for i in range(210):\n",
        "    final_list.append(copy[8*i:8*(i+1)])\n",
        "\n",
        "#Revisar si la nueva lista tiene los valores correctos\n",
        "\"\"\"\n",
        "for val in final_list[:5]:\n",
        "    print(val)\n",
        "\"\"\"\n",
        "\n",
        "data ={\n",
        "    \"area\": [],\n",
        "    \"perimeter\": [],\n",
        "    \"compactness\": [],\n",
        "    \"length of kernel\": [],\n",
        "    \"width of kernel\": [],\n",
        "    \"asymmetry coefficient\": [],\n",
        "    \"length of kernel groove\": [],\n",
        "    \"classification\": []\n",
        "}\n",
        "for sub_list in final_list:\n",
        "    data[\"area\"].append(sub_list[0])\n",
        "    data[\"perimeter\"].append(sub_list[1])\n",
        "    data[\"compactness\"].append(sub_list[2])\n",
        "    data[\"length of kernel\"].append(sub_list[3])\n",
        "    data[\"width of kernel\"].append(sub_list[4])\n",
        "    data[\"asymmetry coefficient\"].append(sub_list[5])\n",
        "    data[\"length of kernel groove\"].append(sub_list[6])\n",
        "    data[\"classification\"].append(sub_list[7])\n",
        "df = pd.DataFrame(data)\n",
        "#print(df)\n",
        "\n",
        "df_dtypes = {\n",
        "    \"area\": float,\n",
        "    \"perimeter\": float,\n",
        "    \"compactness\": float,\n",
        "    \"length of kernel\": float,\n",
        "    \"width of kernel\": float,\n",
        "    \"asymmetry coefficient\": float,\n",
        "    \"length of kernel groove\": float,\n",
        "    \"classification\": int\n",
        "}\n",
        "\n",
        "df = df.astype(df_dtypes)\n",
        "#print(df.dtypes)\n",
        "#print(df.astype(df_dtypes).dtypes)\n",
        "#input(\"ctrl + c para terminar ejecución\")\n",
        "\n",
        "######CLUSTERIZACIÓN INICIAL SIN PREPROCESAMIENTO\n",
        "\n",
        "##importación de librerías\n",
        "\n",
        "#Generales\n",
        "\n",
        "#plt.scatter(df.area, df.classification)\n",
        "#plt.show()\n",
        "\n",
        "#Modelos y metricas\n",
        "\n",
        "#mezclar dataframe\n",
        "df = df.sample(frac=1, random_state=42)\n",
        "#print(df)\n",
        "\n",
        "scoring = [\n",
        "    \"adjusted_mutual_info_score\",\n",
        "    \"adjusted_rand_score\",\n",
        "    \"homogeneity_score\"\n",
        "]\n",
        "\n",
        "#KMEANS\n",
        "param_grid = {\n",
        "    'n_clusters': [1, 2, 3, 4, 5, 10, 15, 20],\n",
        "    'init': ['k-means++', 'random'],\n",
        "    'n_init': ['auto', 1, 10, 100],\n",
        "    'max_iter': [10, 100, 1000],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "kmeans = KMeans()\n",
        "grid_kmeans = GridSearchCV(estimator=kmeans, param_grid=param_grid, scoring=scoring, refit=False)\n",
        "print(\"\\n\\nIniciando entrenamiento de KMEANS\")\n",
        "grid_kmeans.fit(df)\n",
        "print(\"\\n\\nEntrenamiento terminado\")\n",
        "\n",
        "#DBSCAN\n",
        "param_grid = [\n",
        "    {\n",
        "        'eps': [0.01, 0.1, 0.5, 0.9],\n",
        "        'min_samples': [1, 5, 10, 15],\n",
        "        'metric': ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan'],\n",
        "        'algorithm': ['ball_tree', 'kd_tree'],\n",
        "        'leaf_size': [30, 100, 1000],\n",
        "        'n_jobs': [2]\n",
        "    },\n",
        "    {\n",
        "        'eps': [0.01, 0.1, 0.5, 0.9],\n",
        "        'min_samples': [1, 5, 10, 15],\n",
        "        'metric': ['minkowski'],\n",
        "        'p': [2, 3, 4, 5],\n",
        "        'algorithm': ['ball_tree', 'kd_tree'],\n",
        "        'leaf_size': [30, 100, 1000],\n",
        "        'n_jobs': [2]\n",
        "    },\n",
        "    {\n",
        "        'eps': [0.01, 0.1, 0.5, 0.9],\n",
        "        'min_samples': [1, 5, 10, 15],\n",
        "        'metric': ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan'],\n",
        "        'algorithm': ['brute'],\n",
        "        'n_jobs': [2]\n",
        "    },\n",
        "    {\n",
        "        'eps': [0.01, 0.1, 0.5, 0.9],\n",
        "        'min_samples': [1, 5, 10, 15],\n",
        "        'metric': ['minkowski'],\n",
        "        'p': [2, 3, 4, 5],\n",
        "        'algorithm': ['brute'],\n",
        "        'n_jobs': [2]\n",
        "    }\n",
        "]\n",
        "\n",
        "dbscan = DBSCAN()\n",
        "grid_dbscan = GridSearchCV(estimator=dbscan, param_grid=param_grid, scoring=scoring, refit=False)\n",
        "print(\"\\n\\nIniciando entrenamiento de DBSCAN\")\n",
        "grid_dbscan.fit(df)\n",
        "print(\"\\nEntrenamiento terminado\")\n",
        "\n",
        "#Hierarchical (agglomerative)\n",
        "param_grid = [\n",
        "    {\n",
        "        'n_clusters': [2, 3, 4, 5, 10],\n",
        "        'metric': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine'],\n",
        "        'linkage': ['complete', 'average', 'single'],\n",
        "        'compute_distances': [True]\n",
        "    },\n",
        "    {\n",
        "        'n_clusters': [2, 3, 4, 5, 10],\n",
        "        'metric': ['euclidean'],\n",
        "        'linkage': ['ward'],\n",
        "        'compute_distances': [True]\n",
        "    },\n",
        "]\n",
        "\n",
        "hier = AgglomerativeClustering()\n",
        "grid_hier = GridSearchCV(estimator=hier, param_grid=param_grid, scoring=scoring, refit=False)\n",
        "print(\"\\n\\nIniciando entrenamiento de HIERARCHICAL\")\n",
        "grid_hier.fit(df)\n",
        "print(\"\\nEntrenamiento terminado\")\n",
        "\n",
        "print(\"\\n\\t\\tResultados:\")\n",
        "\n",
        "print(\"\\n\\tKMEANS\")\n",
        "print(f\"Best estimator: {grid_kmeans.best_estimator_}\\n\"+\n",
        "      f\"Best score: {grid_kmeans.best_score_}\")\n",
        "\n",
        "print(\"\\n\\tDBSCAN\")\n",
        "print(f\"Best estimator: {grid_dbscan.best_estimator_}\\n\"+\n",
        "      f\"Best score: {grid_dbscan.best_score_}\")\n",
        "\n",
        "print(\"\\n\\tHIERARCHICAL\")\n",
        "print(f\"Best estimator: {grid_hier.best_estimator_}\\n\"+\n",
        "      f\"Best score: {grid_hier.best_score_}\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\\tKMEANS\")\n",
        "results = pd.DataFrame(grid_kmeans.cv_results_).sort_values(by=\"rank_test_score\")\n",
        "print(results)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uKlwh-hQkIKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Billetes Falsos"
      ],
      "metadata": {
        "id": "v95JTHhKjS_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xubyjnOUfUqN"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importar librerías"
      ],
      "metadata": {
        "id": "4BRDPHFRfxAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "QaIPZsOnflaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Obtener Dataset de billetes falsos"
      ],
      "metadata": {
        "id": "ICgLbMa3f6PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset\n",
        "banknote_authentication = fetch_ucirepo(id=267)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = banknote_authentication.data.features\n",
        "y = banknote_authentication.data.targets"
      ],
      "metadata": {
        "id": "8J2ADXbrfnpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploración de datos"
      ],
      "metadata": {
        "id": "vfv78lkjgC03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "banknote = pd.DataFrame(data=banknote_authentication.data.features, columns=banknote_authentication.data.feature_names)\n",
        "banknote['class'] = banknote_authentication.data.targets\n",
        "banknote.head()"
      ],
      "metadata": {
        "id": "xC0PNgPAfuli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}